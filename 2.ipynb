{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/st24hour/tutorial/blob/master/2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0TD5ZrvEMbhZ"
      },
      "cell_type": "markdown",
      "source": [
        "**Copyright 2018 The TensorFlow Authors**.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\").\n",
        "\n",
        "# Session2. Generating Handwritten Digits with DCGAN"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ITZuApL56Mny"
      },
      "cell_type": "markdown",
      "source": [
        "This tutorial demonstrates how to generate images of handwritten digits using a Deep Convolutional Generative Adversarial Network ([DCGAN](https://arxiv.org/pdf/1511.06434.pdf)). The code is written in [tf.keras](https://www.tensorflow.org/programmers_guide/keras) with [eager execution](https://www.tensorflow.org/programmers_guide/eager) enabled. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "u_2z-B3piVsw",
        "outputId": "838608f6-aa30-4b95-a8a9-eaae6f18dfa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "# Install imgeio in order to generate an animated gif showing the image generating process\n",
        "!pip install imageio"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "e1_Y75QXJS6h"
      },
      "cell_type": "markdown",
      "source": [
        "### Import TensorFlow and enable eager execution"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "iYn4MdZnKCey"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the dataset\n",
        "\n",
        "We are going to use the MNIST dataset to train the generator and the discriminator. The generator will generate handwritten digits resembling the MNIST data."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "a4fYMGxGhrna",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NFC2ghIdiZYE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S4PIDhoDLbsZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PIGN6ouoQxt3"
      },
      "cell_type": "markdown",
      "source": [
        "### Use tf.data to create batches and shuffle the dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-yKCCQOoJ7cn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "THY-sZMiQ4UV"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the models\n",
        "\n",
        "We will use tf.keras [Sequential API](https://www.tensorflow.org/guide/keras#sequential_model) to define the generator and discriminator models."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-tEyxE-GMC48"
      },
      "cell_type": "markdown",
      "source": [
        "### The Generator Model\n",
        "\n",
        "The generator is responsible for creating convincing images that are good enough to fool the discriminator. The network architecture for the generator consists of [Conv2DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose) (Upsampling) layers. We start with a fully connected layer and upsample the image two times in order to reach the desired image size of 28x28x1. We increase the width and height, and reduce the depth as we move through the layers in the network. We use [Leaky ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU) activation for each layer except for the last one where we use a tanh activation."
      ]
    },
    {
      "metadata": {
        "id": "6bpTcDqoLWjY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "      \n",
        "    model.add(tf.keras.layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)  \n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)    \n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "  \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "D0IKnaCtg6WE"
      },
      "cell_type": "markdown",
      "source": [
        "### The Discriminator model\n",
        "\n",
        "The discriminator is responsible for distinguishing fake images from real images. It's similar to a regular CNN-based image classifier."
      ]
    },
    {
      "metadata": {
        "id": "dw2tPLmk2pEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "      \n",
        "    model.add(tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "       \n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "     \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gDkA05NE6QMs",
        "outputId": "5e00bced-8af8-4996-b15c-56b4f7e55551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0FMYgY_mPfTi"
      },
      "cell_type": "markdown",
      "source": [
        "## Define the loss functions and the optimizer\n",
        "\n",
        "Let's define the loss functions and the optimizers for the generator and the discriminator.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Jd-3GCUEiKtv"
      },
      "cell_type": "markdown",
      "source": [
        "### Generator loss\n",
        "The generator loss is a sigmoid cross entropy loss of the generated images and an array of ones, since the generator is trying to generate fake images that resemble the real images."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "90BIcCKcDMxz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator_loss(generated_output):\n",
        "    return tf.losses.sigmoid_cross_entropy(tf.ones_like(generated_output), generated_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PKY_iPSPNWoj"
      },
      "cell_type": "markdown",
      "source": [
        "### Discriminator loss\n",
        "\n",
        "The discriminator loss function takes two inputs: real images, and generated images. Here is how to calculate the discriminator loss:\n",
        "1. Calculate real_loss which is a sigmoid cross entropy loss of the real images and an array of ones (since these are the real images).\n",
        "2. Calculate generated_loss which is a sigmoid cross entropy loss of the generated images and an array of zeros (since these are the fake images).\n",
        "3. Calculate the total_loss as the sum of real_loss and generated_loss."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wkMNfBWlT-PV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, generated_output):\n",
        "    # [1,1,...,1] with real output since it is true and we want our generated examples to look like it\n",
        "    real_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(real_output), logits=real_output)\n",
        "\n",
        "    # [0,0,...,0] with generated images since they are fake\n",
        "    generated_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.zeros_like(generated_output), logits=generated_output)\n",
        "\n",
        "    total_loss = real_loss + generated_loss\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MgIc7i0th_Iu"
      },
      "cell_type": "markdown",
      "source": [
        "The discriminator and the generator optimizers are different since we will train two networks separately."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iWCn_PVdEJZ7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.train.AdamOptimizer(1e-4)\n",
        "discriminator_optimizer = tf.train.AdamOptimizer(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mWtinsGDPJlV"
      },
      "cell_type": "markdown",
      "source": [
        "**Checkpoints (Object-based saving)**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CA1w-7s2POEy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Rw1fkAczTQYh"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up GANs for Training\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5QC5BABamh_c"
      },
      "cell_type": "markdown",
      "source": [
        "Now it's time to put together the generator and discriminator to set up the Generative Adversarial Networks, as you see in the diagam at the beginning of the tutorial."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Ff6oN6PZX27n"
      },
      "cell_type": "markdown",
      "source": [
        "**Define training parameters**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NS2GWywBbAWo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We'll re-use this random vector used to seed the generator so\n",
        "# it will be easier to see the improvement over time.\n",
        "random_vector_for_generation = tf.random_normal([num_examples_to_generate,\n",
        "                                                 noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jylSonrqSWfi"
      },
      "cell_type": "markdown",
      "source": [
        "**Define training method**\n",
        "\n",
        "We start by iterating over the dataset. The generator is given a random vector as an input which is processed to  output an image looking like a handwritten digit. The discriminator is then shown the real MNIST images as well as the generated images.\n",
        "\n",
        "Next, we calculate the generator and the discriminator loss. Then, we calculate the gradients of loss with respect to both the generator and the discriminator variables."
      ]
    },
    {
      "metadata": {
        "id": "3t5ibNo05jCB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_step(images):\n",
        "   # generating noise from a normal distribution\n",
        "      noise = tf.random_normal([BATCH_SIZE, noise_dim])\n",
        "      \n",
        "      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "      \n",
        "        real_output = discriminator(images, training=True)\n",
        "        generated_output = discriminator(generated_images, training=True)\n",
        "         \n",
        "        gen_loss = generator_loss(generated_output)\n",
        "        disc_loss = discriminator_loss(real_output, generated_output)\n",
        "        \n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.variables)\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.variables)\n",
        "      \n",
        "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.variables))\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6TSZgwc2BUQ-"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "This model takes about ~30 seconds per epoch to train on a single Tesla K80 on Colab, as of October 2018. \n",
        "\n",
        "Eager execution can be slower than executing the equivalent graph as it can't benefit from whole-program optimizations on the graph, and also incurs overheads of interpreting Python code. By using [tf.contrib.eager.defun](https://www.tensorflow.org/api_docs/python/tf/contrib/eager/defun) to create graph functions, we get a ~20 secs/epoch performance boost (from ~50 secs/epoch down to ~30 secs/epoch). This way we get the best of both eager execution (easier for debugging) and graph mode (better performance)."
      ]
    },
    {
      "metadata": {
        "id": "Iwya07_j5p2A",
        "colab_type": "code",
        "outputId": "f0163a90-52d2-4728-c554-c808941c5583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "train_step = tf.contrib.eager.defun(train_step)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2M7LmLtGEMQJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):  \n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    \n",
        "    for images in dataset:\n",
        "      train_step(images)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                               epoch + 1,\n",
        "                               random_vector_for_generation)\n",
        "    \n",
        "    # saving (checkpoint) the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "    print ('Time taken for epoch {} is {} sec'.format(epoch + 1,\n",
        "                                                      time.time()-start))\n",
        "  # generating after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           random_vector_for_generation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2aFF7Hk3XdeW"
      },
      "cell_type": "markdown",
      "source": [
        "**Generate and save images**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RmdVsmvhPxyy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # make sure the training parameter is set to False because we\n",
        "  # don't want to train the batchnorm layer when doing inference.\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "  \n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "        \n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "dZrd4CdjR-Fp"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the GANs\n",
        "We will call the train() method defined above to train the generator and discriminator simultaneously. Note, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n",
        "\n",
        "At the beginning of the training, the generated images look like random noise. As training progresses, you can see the generated digits look increasingly real. After 50 epochs, they look very much like the MNIST digits."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ly3UN0SLLY2l",
        "outputId": "863aec9c-9911-4232-bf14-f41bc79ec1e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1787
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAD7CAYAAACFUEoIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABQlwqgAUJQIowJAUSLM/wN7dSuUlcQ0kgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time taken for epoch 6 is 25.692227602005005 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-3bfe38106dd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train(train_dataset, EPOCHS)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-a3c4cb71473d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \"\"\"\n\u001b[1;32m    383\u001b[0m     return self._call_flat(\n\u001b[0;32m--> 384\u001b[0;31m         (t for t in nest.flatten((args, kwargs))\n\u001b[0m\u001b[1;32m    385\u001b[0m          if isinstance(\n\u001b[1;32m    386\u001b[0m              t, (ops.Tensor, resource_variable_ops.ResourceVariable))))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    267\u001b[0m           \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction_call_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_proto_serialized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m           executor_type=function_call_options.executor_type)\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mpartitioned_call\u001b[0;34m(args, f, tout, executing_eagerly, config, executor_type)\u001b[0m\n\u001b[1;32m   1081\u001b[0m       outputs = gen_functional_ops.stateful_partitioned_call(\n\u001b[1;32m   1082\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_proto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m           executor_type=executor_type)\n\u001b[0m\u001b[1;32m   1084\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m       outputs = gen_functional_ops.partitioned_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_functional_ops.py\u001b[0m in \u001b[0;36mstateful_partitioned_call\u001b[0;34m(args, Tout, f, config, config_proto, executor_type, name)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;34m\"StatefulPartitionedCall\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;34m\"Tout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \"executor_type\", executor_type)\n\u001b[0m\u001b[1;32m    484\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rfM4YcPVPkNO"
      },
      "cell_type": "markdown",
      "source": [
        "**Restore the latest checkpoint**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XhXsd0srPo8c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "P4M_vIbUi7c0"
      },
      "cell_type": "markdown",
      "source": [
        "## Generated images \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mLskt7EfXAjr"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "After training, its time to generate some images! \n",
        "The last step is to plot the generated images and voila!\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WfO5wCdclHGL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5x3q9_Oe5q0A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "display_image(EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NywiH3nL8guF"
      },
      "cell_type": "markdown",
      "source": [
        "**Generate a GIF of all the saved images**\n",
        "\n",
        "We will use imageio to create an animated gif using all the images saved during training."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IGKQgENQ8lEI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with imageio.get_writer('dcgan.gif', mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "    \n",
        "# this is a hack to display the gif inside the notebook\n",
        "os.system('cp dcgan.gif dcgan.gif.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cGhC3-fMWSwl"
      },
      "cell_type": "markdown",
      "source": [
        "Display the animated gif with all the mages generated during the training of GANs."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uV0yiKpzNP1b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "display.Image(filename=\"dcgan.gif.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}