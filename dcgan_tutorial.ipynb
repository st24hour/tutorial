{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/st24hour/tutorial/blob/master/dcgan_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_jQ1tEQCxwRx"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "V_sgB_5dx1f1",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rF2x3qooyBTI"
      },
      "source": [
        "# Deep Convolutional Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ITZuApL56Mny"
      },
      "source": [
        "이 튜토리얼에서 우리는 [Deep Convolutional Generative Adversarial Network](https://arxiv.org/pdf/1511.06434.pdf) (DCGAN)을 사용하여 어떻게 handwritten 숫자들을 만드는 네트워크를 학습시킬지를 배울 것입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2MbKJY38Puy9"
      },
      "source": [
        "## GAN이란?\n",
        "[Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) (GANs) 는 최근 computer science 분야에서 가장 흥미로운 아이디어 중에 하나입니다. 두 개의 모델은 적대적인 과정을 통해 동시다발적으로 훈련됩니다. *Generator* (\"예술가\")는 진짜처럼 보이는 이미지를 만드는 법을 배우고, *Discriminator*(\"비평가\")는 진짜 이미지와 가짜 이미지를 구분하는 법을 배웁니다.\n",
        "\n",
        "![A diagram of a generator and discriminator](https://tensorflow.org/beta/tutorials/generative/images/gan1.png)\n",
        "\n",
        "*Generator*는 점진적으로 더 진짜 같은 이미지를 만들게 되고 *Discriminator*는 더 잘 진짜와 가짜를 구분하게 됩니다. \n",
        "\n",
        "![A second diagram of a generator and discriminator](https://tensorflow.org/beta/tutorials/generative/images/gan2.png)\n",
        "\n",
        "이 코드를 통해 우리는 MNIST 데이터셋을 사용하여 GAN을 학습해볼 것입니다. 아래의 애니메이션은 *Generator*로부터 50 epoch을 거쳐 만들어진 여러 개의 이미지들입니다. 이 이미지들은 random noise로부터 시작해서 점점 시간이 갈 수록 handwritten 숫자의 형상을 갖추게 됩니다.\n",
        "\n",
        "![sample output](https://tensorflow.org/images/gan/dcgan.gif)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKumTwKVgePx",
        "colab_type": "text"
      },
      "source": [
        "## DCGAN 튜토리얼\n",
        "\n",
        "이제부터 어떻게 네트워크를 만들고 GAN학습을 시킬지를 배워봅시다.\n",
        "순서는 다음과 같습니다.\n",
        "1. Tensorflow와 다른 library들을 불러온다.\n",
        "2. 데이터셋을 불러온다.\n",
        "3. 모델을 만든다.\n",
        "4. loss와 optimizer를 정의한다.\n",
        "5. Training loop를 정의한다.\n",
        "6. Training!\n",
        "7. Test\n",
        "\n",
        "그럼 하나씩 진행해보도록 합시다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "### Import Tensorflow and other libraries\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J5oue0oqCkZZ",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g5RstiiB8V-z",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta1 #tensorflow gpu 버전을 설치합니다\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WZKbyU2-AiY-",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf # tensorflow를 import해줍니다"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wx-zNbLqB4K8",
        "colab": {}
      },
      "source": [
        "tf.__version__ # 내가 사용할 tensorflow의 버전을 나타냅니다"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YzTlj4YdCip_",
        "colab": {}
      },
      "source": [
        "# 나중에 GIF를 생성하기 위해서 import해줍니다\n",
        "!pip install imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "### Load and prepare the dataset\n",
        "\n",
        "MNIST 데이터셋을 이용하여 Generator와 Discriminator를 학습시켜봅시다. 학습이 끝나면 Generator는 MNIST 데이터를 닮은 handwritten 숫자들을 생성할 것입니다.\n",
        "\n",
        "주어진 정보들을 이용하여 빈 칸을 채워보세요! ([    ]가 빈 칸을 나타냅니다. 괄호를 지우고 알맞은 코드를 써주세요)\n",
        "\n",
        "1. MNIST 데이터는 28x28x1의 dimension을 갖고 있습니다. 받아온 train_images를 (train_image의 갯수, width, height, channel)로 reshape한 뒤 float32로 casting해줍니다.\n",
        "2. [0, 255] 범위로 이루어진 train_images를 [-1, 1]의 범위로 normalize해주기 위해 이미지에서 127.5를 뺀 뒤 127.5로 나눠줍니다. train_images에서 바로 빼고 나눠주시면 됩니다.\n",
        "(픽셀의 값이 0일 경우 (0 - 127.5)/127.5=-1, 255일 경우 (255 - 127.5)/127.5=1이 됩니다. 이 과정을 통해  기존의 0과 255사이의 값으로 이루어진 이미지가 -1과 1사이의 값을 가지도록 normalize를 해주는 것입니다.)\n",
        "3. BUFFER SIZE는 60000입니다.\n",
        "4. BATCH SIZE는 256입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4fYMGxGhrna",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NFC2ghIdiZYE",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape([      ]).astype('[      ]') # 1번\n",
        "train_images = [             ] # 2번"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4PIDhoDLbsZ",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = [          ] # 3번\n",
        "BATCH_SIZE = [          ] # 4번"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-yKCCQOoJ7cn",
        "colab": {}
      },
      "source": [
        "# 데이터를 shuffle하고 batch를 받아옵니다\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "### Create the models\n",
        "이제 Generator와 Discriminator 모델을 만들어봅시다!\n",
        "Generator와 Discriminator들은 모두  [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model).를 사용하여 정의할 것입니다.\n",
        "\n",
        "우리가 만들 Generator와 Discriminator의 구조는 아래 그림들과 같습니다.\n",
        "\n",
        "빈 칸을 채워서 그림과 맞는 모델을 만들어보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-tEyxE-GMC48"
      },
      "source": [
        "### The Generator\n",
        "\n",
        "Generator는 `tf.keras.layers.Conv2DTranspose` (unsampling) 레이어를 사용하여 seed(random noise)로부터 이미지를 생성합니다. 먼저 `Dense` 레이어에서 이 seed를 input으로 받은 뒤에 원본 이미지 크기(28x28x1)에 도달할 때까지 unsampling을 여러번 반복합니다. `tf.keras.layers.BatchNormalization`과 `tf.keras.layers.LeakyReLU` activation을 각 블럭의 마지막에 추가해줍니다.\n",
        "![generator](https://docs.google.com/uc?export=download&id=12hZMMHiHbqsiDwGKi7J87T-Ic_y8s6p5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6bpTcDqoLWjY",
        "colab": {}
      },
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense([      ], use_bias=False, input_shape=([     ],))) # 빈칸을 채워주세요\n",
        "    model.add(layers.[       ]()) # 빈칸을 채워주세요\n",
        "    model.add(layers.[       ]()) # 빈칸을 채워주세요\n",
        "\n",
        "    model.add(layers.Reshape(([      ]))) # 빈칸을 채워주세요\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose([    ], ([     ]), strides=([     ]), padding='same', use_bias=False)) # 빈칸을 채워주세요\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.[       ]()) # 빈칸을 채워주세요\n",
        "    model.add(layers.[       ]()) # 빈칸을 채워주세요\n",
        "\n",
        "    model.add(layers.Conv2DTranspose([    ], ([     ]), strides=([     ]), padding='same', use_bias=False)) # 빈칸을 채워주세요\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.[       ]() # 빈칸을 채워주세요\n",
        "    model.add(layers.[       ]())# 빈칸을 채워주세요\n",
        "\n",
        "    model.add(layers.Conv2DTranspose([     ], ([     ]), strides=([      ]), padding='same', use_bias=False, activation='tanh')) # 빈칸을 채워주세요\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GyWgG09LCSJl"
      },
      "source": [
        "Generator를 사용하여 이미지를 생성하도록 합니다.\n",
        "1. 1x100 dimension을 가진 noise를 정의해줍시다. \n",
        "2. 만들어진 이미지 generated_image는 generator에 noise를 input으로 넣어줌으로써 생성됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gl7jcC7TdPTG",
        "colab": {}
      },
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([     ]) # 1번\n",
        "generated_image = generator([     ], training=False) # 2번\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D0IKnaCtg6WE"
      },
      "source": [
        "### The Discriminator\n",
        "Discriminator는 CNN-based 이미지 분류기입니다.\n",
        "\n",
        "빈 칸을 채워 Discriminator의 구성을 완료합시다.\n",
        "![generator](https://docs.google.com/uc?export=download&id=18fiJbjonI34sO0CJJ-XxhLHXpFBIAlnU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dw2tPLmk2pEP",
        "colab": {}
      },
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D([     ], ([     ]), strides=([      ]), padding='same',\n",
        "                                     input_shape=[28, 28, 1])) # 빈칸을 채워주세요\n",
        "    model.add(layers.[       ]()) # 빈칸을 채워주세요\n",
        "    model.add(layers.[       ]([   ])) # 빈칸을 채워주세요\n",
        "\n",
        "    model.add(layers.Conv2D([    ], ([    ]), strides=([      ]), padding='same')) # 빈칸을 채워주세요\n",
        "    model.add(layers.[       ]()) # 빈칸을 채워주세요\n",
        "    model.add(layers.[       ]([   ])) # 빈칸을 채워주세요\n",
        "\n",
        "    model.add(layers.[     ]()) # 빈칸을 채워주세요\n",
        "    model.add(layers.[     ](1)) # 빈칸을 채워주세요\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QhPneagzCaQv"
      },
      "source": [
        "Discriminator(아직 training하지 않은)를 사용하여 만들어진 이미지가 진짜인지 가짜인지 구별하도록 합니다. 모델은 진짜 이미지를 받았을 때는 positivie한 값을 가짜 이미지를 받았을 때는 negative한 값을 내보내도록 학습될 것 입니다.\n",
        "\n",
        "1. Discriminator(discriminator)가 만들어진 이미지(generated_image)를 받아 결정값을(decision) 내보내도록 합시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDkA05NE6QMs",
        "colab": {}
      },
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator([      ]) # 1번\n",
        "print (decision)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## Define the loss and optimizers\n",
        "\n",
        "두 모델을 위해 loss functions과 optimizer를 정의해줍시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "psQfmXxYKU3X",
        "colab": {}
      },
      "source": [
        "# 이 메서드는 크로스 엔트로피 손실함수 (cross entropy loss)를 계산하기 위해 헬퍼 (helper) 함수를 반환합니다.\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PKY_iPSPNWoj"
      },
      "source": [
        "### Discriminator loss\n",
        "\n",
        "이 loss는 Discriminator가 얼마나 잘 진짜 이미지와 가짜 이미지를 구별해내는 지를 보여줄 것입니다. Discriminator가 진짜 이미지를 받아서 예측해낸 값과 1로 이루어진 array를 비교하고, 가짜 이미지(만들어진 이미지)를 받아서 예측해낸 값과 0으로 이루어진 array를 비교할 것입니다.\n",
        "\n",
        "1. real_output과 같은 크기를 가진 1로 이루어진 array와 real_output과의 cross entropy를 계산하여 real_loss라고 정의해줍시다. (Hint: tf.ones_like)\n",
        "2. fake_output과 같은 크기를 가진 0로 이루어진 array와 fake_output과의 cross entropy를 계산하여 fake_loss라고 정의해줍시다. (Hint: tf.zeros_like)\n",
        "3. real_loss와 fake_loss를 합해 total_loss라고 정의해줍시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wkMNfBWlT-PV",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy([       ]) # 1번\n",
        "    fake_loss = cross_entropy([       ]) # 2번\n",
        "    total_loss = [       ] # 3번\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jd-3GCUEiKtv"
      },
      "source": [
        "### Generator loss\n",
        "\n",
        "Generator의 loss는 얼마나 discriminator를 잘 속였는지를 값으로 보여줍니다. 직관적으로, 만약 Generator가 잘 하고 있다면 discriminator는 가짜 이미지를 진짜라고 판단할 것입니다 (or 1). 여기서 우리는 Generator가 만든 이미지(fake_output)이 Discriminator에 들어가서 나온 값이 1에 가까워지도록 할 것입니다.\n",
        "1. fake_output과 같은 크기를 가진 1로 이루어진 array와 fake_output과의 cross entropy를 계산하는 함수를 정의해줍시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "90BIcCKcDMxz",
        "colab": {}
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy([      ], fake_output) # 1번"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MgIc7i0th_Iu"
      },
      "source": [
        "Discriminator와 Generator는 각각 학습되기 때문에 다른 optimizer를 정의해주어야합니다.\n",
        "1. 두 개의 optimizer를 각각 Adam Optimizer를 learning rate 1e-4로 정의해줍시다. ( Hint: tf.keras.optimizers.Adam(*learning_rate*))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iWCn_PVdEJZ7",
        "colab": {}
      },
      "source": [
        "generator_optimizer = [      ] # 1번\n",
        "discriminator_optimizer = [      ] # 1번"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mWtinsGDPJlV"
      },
      "source": [
        "### Save checkpoints\n",
        "\n",
        "모델을 저장하고 다시 불러오기 위해 checkpoint를 만들어줍시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CA1w-7s2POEy",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## Define the training loop\n",
        "\n",
        "1. 우리는 50 epoch을 돌려 training 시킬 것입니다.\n",
        "2. 우리가 사용할 noise의 dimension은 100입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NS2GWywBbAWo",
        "colab": {}
      },
      "source": [
        "EPOCHS = [    ] # 1번\n",
        "noise_dim = [    ] # 2번\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "\n",
        "# animated GIF를 생성하기 위한 seed 생성\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jylSonrqSWfi"
      },
      "source": [
        "Training loop는 Generator가 random noise를 input으로 받으면서부터 시작됩니다. seed는 이미지를 만들기 위해 쓰입니다. Discriminator는 진짜 이미지(Training set에 있는)와 가짜 이미지(Generator가 만든)를 구분하도록 학습합니다. 각 model의 loss를 각각 계산한뒤 gradient를 이용하여 Generator와 Discriminator를 업데이트합시다.\n",
        "\n",
        "1. Batch Size x Noise Dimension 크기의 noise를 생성합시다. (Hint: tf.random.normal)\n",
        "2. 위에서 정의한 generator에 noise를 input으로 주어 generated_images를 생성합니다. (Hint: training=True를 설정해줍시다)\n",
        "3. 위에서 정의한 discriminator에 진짜 이미지(images)를 넣어 real_output을 만듭니다. (Hint: training=True를 설정해줍시다)\n",
        "4. 위에서 정의한 discriminator에 가짜 이미지를 넣어(generated_images) fake_output을 만듭니다. (Hint: training=True를 설정해줍시다)\n",
        "5. 위에서 정의한 generator_loss에 fake_output을 넣어 gen_loss를 계산합니다.\n",
        "5. real_output과 fake_output을 이용하여 disc_loss를 계산합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3t5ibNo05jCB",
        "colab": {}
      },
      "source": [
        "# `tf.function`이 어떻게 사용되는지 주목해 주세요.\n",
        "# 이 데코레이터는 함수를 \"컴파일\"합니다.\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = [      ] # 1번\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = [      ] # 2번\n",
        "\n",
        "      real_output = [      ] # 3번\n",
        "      fake_output = [      ] # 4번\n",
        "\n",
        "      gen_loss = [      ] # 5번\n",
        "      disc_loss = [      ] # 6번\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCnEK4kHrW67",
        "colab_type": "text"
      },
      "source": [
        "## Train 함수를 정의해봅시다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2M7LmLtGEMQJ",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2aFF7Hk3XdeW"
      },
      "source": [
        "**Generate and save images**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RmdVsmvhPxyy",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dZrd4CdjR-Fp"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "위에서 정의한 `train()` 함수를 불러 Generator와 Discriminator를 동시에 학습합니다. GAN을 학습하는 것은 까다롭습니다. Generator와 Discriminator가 서로를 overpower하지 않도록 해주는 것이 중요합니다.\n",
        "\n",
        "Training을 시작할 때 만들어진 이미지는 random한 noise처럼 보입니다. 그러나 학습이 진행되면서 만들어진 숫자들은 진짜처럼 보이기 시작합니다. 50 epoch이 지나면 MNIST 숫자를 닮은 이미지가 생성될 것 입니다.\n",
        "\n",
        "1. 위에서 정의한 train 함수에 넣어줘야하는 인자를 넣어 학습을 시작해줍시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ly3UN0SLLY2l",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "train([    ], [    ]) # 1번"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rfM4YcPVPkNO"
      },
      "source": [
        "학습이 다 끝나면 가장 최근의 checkpoint를 불러 test해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XhXsd0srPo8c",
        "colab": {}
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P4M_vIbUi7c0"
      },
      "source": [
        "## Create a GIF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WfO5wCdclHGL",
        "colab": {}
      },
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5x3q9_Oe5q0A",
        "colab": {}
      },
      "source": [
        "display_image(EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NywiH3nL8guF"
      },
      "source": [
        "`imageio` 라이브러리를 사용하여 training 도중 저장 된 이미지들로 gif를 만들어봅시다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IGKQgENQ8lEI",
        "colab": {}
      },
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import IPython\n",
        "if IPython.version_info > (6,2,0,''):\n",
        "  display.Image(filename=anim_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uV0yiKpzNP1b",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(anim_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k6qC-SbjK0yW"
      },
      "source": [
        "## Report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xjjkT9KAK6H7"
      },
      "source": [
        "1. 레포트에 학습시킨 모델의 1epoch, 5epoch, 15epoch, 30epoch, 50epoch의 결과 이미지들을 첨부해주세요.\n",
        "2. noise의 dimension을 10, 50, 200으로 바꾸어 학습시켜본 뒤 결과 이미지를 첨부해주세요.\n",
        "\n",
        "juseung_yun@kaist.ac.kr로 레포트를 제출해주세요!"
      ]
    }
  ]
}